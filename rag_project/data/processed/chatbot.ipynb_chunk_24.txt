gchaincompublic04402eaa29e64bb1aa91885b730b6c21r  Streaming Now weve got a functioning chatbot However one really important UX consideration for chatbot applications is streaming LLMs can sometimes take a while to respond and so in order to improve the user experience one thing that most applications do is stream back each token as it is generated This allows the user to see progress Its actually super easy to do this By default stream in our LangGraph application streams application steps in this case the 