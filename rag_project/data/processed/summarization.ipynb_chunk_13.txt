marize in a single LLM call stuff We can use create_stuff_documents_chainhttpspythonlangchaincomapi_referencelangchainchainslangchainchainscombine_documentsstuffcreate_stuff_documents_chainhtml especially if using larger context window models such as  128k token OpenAI gpt4o  200k token Anthropic claude35sonnet20240620 The chain will take a list of documents insert them all into a prompt and pass that prompt to an LLM  Streaming Note that we can also stream the result tokenbytoken  Go deeper  You can easily