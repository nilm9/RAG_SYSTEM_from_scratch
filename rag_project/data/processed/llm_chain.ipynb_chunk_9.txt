enaiformat The following are equivalent python modelinvokeHello modelinvokerole user content Hello modelinvokeHumanMessageHello   Streaming Because chat models are Runnablesdocsconceptsrunnables they expose a standard interface that includes async and streaming modes of invocation This allows us to stream individual tokens from a chat model You can find more details on streaming chat model outputs in this guidedocshow_tochat_streaming  Prompt Templates Right now we are passing a list of messages directly in