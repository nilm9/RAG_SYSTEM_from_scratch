ompt the chat model receives along with tokendocsconceptstokens usage information latency standard model parametersdocsconceptschat_modelsstandardparameters such as temperature and other information  Conclusion Thats it In this tutorial youve learned how to create your first simple LLM application Youve learned how to work with language models how to create a prompt template and how to get great observability into applications you create with LangSmith This just scratches the surface of what you will want t