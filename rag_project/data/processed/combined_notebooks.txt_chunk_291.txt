n answer For generation we will use the chat model selected at the start of the tutorialdocstutorialsragcomponents Well use a prompt for RAG that is checked into the LangChain prompt hub herehttpssmithlangchaincomhubrlmragprompt from langchain import hub prompt  hubpullrlmragprompt example_messages  promptinvoke context context goes here question question goes here to_messages assert lenexample_messages  1 printexample_messages0content Well use LangGraphhttpslangchainaigithubiolanggraph to tie together the 