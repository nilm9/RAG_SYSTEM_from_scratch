 context window of many models Even for those models that could fit the full post in their context window models can struggle to find information in very long inputs To handle this well split the Document into chunks for embedding and vector storage This should help us retrieve only the most relevant parts of the blog post at run time As in the semantic search tutorialdocstutorialsretrievers we use a RecursiveCharacterTextSplitterdocshow_torecursive_text_splitter which will recursively split the document us